{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02753dab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### 용머리해안\n",
      "  place_name        place_location place_feature place_star operating_time\n",
      "0      용머리해안  제주특별자치도 서귀포시 안덕면 사계리       해수욕장,해변             09:00 ~ 17:00\n",
      "#### 용머리해안 공영주차장\n",
      "    place_name                          place_location place_feature  \\\n",
      "0  용머리해안 공영주차장  제주특별자치도 서귀포시 안덕면 사계남로216번길 28 (우)63528         공영주차장   \n",
      "\n",
      "  place_star operating_time  \n",
      "0       1.3점                 \n",
      "#### 용머리해안 기후변화홍보관\n",
      "      place_name                             place_location place_feature  \\\n",
      "0  용머리해안 기후변화홍보관  제주특별자치도 서귀포시 안덕면 사계남로216번길 24-34 (우)63528           전시관   \n",
      "\n",
      "  place_star operating_time  \n",
      "0             09:00 ~ 18:00  \n",
      "#### 용머리해안매표소\n",
      "  place_name              place_location place_feature place_star  \\\n",
      "0   용머리해안매표소  제주특별자치도 서귀포시 안덕면 사계리 112-3           매표소              \n",
      "\n",
      "  operating_time  \n",
      "0                 \n",
      "#### 용머리해안 전기차충전소\n",
      "     place_name                                     place_location  \\\n",
      "0  용머리해안 전기차충전소  제주특별자치도 서귀포시 안덕면 사계남로216번길 28 산방산랜드 근처 공영주차장 위...   \n",
      "\n",
      "  place_feature place_star operating_time  \n",
      "0     전기자동차 충전소                            \n",
      "not found\n",
      "  place_name place_location place_feature place_star operating_time\n",
      "0                                                                  \n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##############################################################  ############\n",
    "##################### variable related selenium ##########################\n",
    "##########################################################################\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('lang=ko_KR')\n",
    "chromedriver_path = \"C:/chromedriver\"\n",
    "driver = webdriver.Chrome(os.path.join(os.getcwd(), chromedriver_path), options=options)  # chromedriver 열기\n",
    "    \n",
    "def search(place):\n",
    "    global driver\n",
    "\n",
    "    search_area = driver.find_element_by_xpath('//*[@id=\"search.keyword.query\"]')  # 검색 창\n",
    "    search_area.send_keys(place)  # 검색어 입력\n",
    "    driver.find_element_by_xpath('//*[@id=\"search.keyword.submit\"]').send_keys(Keys.ENTER)  # Enter로 검색\n",
    "    sleep(1)\n",
    "\n",
    "    # 검색된 정보가 있는 경우에만 탐색\n",
    "    # 1번 페이지 place list 읽기\n",
    "    html = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    place_lists = soup.select('.placelist > .PlaceItem') # 검색된 장소 목록\n",
    "\n",
    "    # 검색된 첫 페이지 장소 목록 크롤링하기\n",
    "    crawling(place, place_lists)\n",
    "    search_area.clear()\n",
    "    \n",
    "    # 우선 더보기 클릭해서 2페이지\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"info.search.place.more\"]').send_keys(Keys.ENTER)\n",
    "        sleep(1)\n",
    "\n",
    "        # 2~ 5페이지 읽기\n",
    "        for i in range(2, 6):\n",
    "            # 페이지 넘기기\n",
    "            xPath = '//*[@id=\"info.search.page.no' + str(i) + '\"]'\n",
    "            driver.find_element_by_xpath(xPath).send_keys(Keys.ENTER)\n",
    "            sleep(1)\n",
    "\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            place_lists = soup.select('.placelist > .PlaceItem') # 장소 목록 list\n",
    "\n",
    "            crawling(place, place_lists)\n",
    "\n",
    "    except ElementNotInteractableException:\n",
    "        print('not found')\n",
    "    finally:\n",
    "        search_area.clear()\n",
    "        \n",
    "def crawling(place, place_lists):\n",
    "    \n",
    "    while_flag = False\n",
    "    for i, place in enumerate(place_lists):\n",
    "        place_name = place.select('.head_item > .tit_name > .link_name')[0].text  # place name\n",
    "#         place_address = place.select('.info_item > .addr > p')[0].text  # place address\n",
    "#         element = driver.find_element(By.XPATH, '//*[@id=\"info.search.place.list\"]/li[2]/div[5]/div[2]/p[2]').text\n",
    "        \n",
    "        \n",
    "        detail_page_xpath = '//*[@id=\"info.search.place.list\"]/li[' + str(i + 1) + ']/div[5]/div[4]/a[1]'\n",
    "        driver.find_element_by_xpath(detail_page_xpath).send_keys(Keys.ENTER)\n",
    "        driver.switch_to.window(driver.window_handles[-1])  # 상세정보 탭으로 변환\n",
    "        sleep(1)\n",
    "\n",
    "        print('####', place_name)\n",
    "        \n",
    "        # 첫 페이지\n",
    "        extract_data(place_name)\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])  # 검색 탭으로 전환\n",
    "        \n",
    "def find_xpath(xpath):\n",
    "    global driver\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_element_by_xpath(xpath)\n",
    "        return element\n",
    "    except NoSuchElementException:\n",
    "        return None\n",
    "\n",
    "def find_element(xpath):\n",
    "    global driver\n",
    "\n",
    "    data_element = find_xpath(xpath)\n",
    "    \n",
    "    if data_element is not None:\n",
    "        data = data_element.text\n",
    "    else:\n",
    "        data = \"\"\n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_data(place_name):\n",
    "    global driver\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # 관광지 이름\n",
    "    place_name = find_element('//*[@id=\"mArticle\"]/div[1]/div[1]/div[2]/div/h2')\n",
    "    # 관광지 주소\n",
    "    place_location = find_element('//*[@id=\"mArticle\"]/div[1]/div[2]/div[1]/div/span[1]')\n",
    "    # 관광지 분류    \n",
    "    place_feature = find_element('//*[@id=\"mArticle\"]/div[1]/div[1]/div[2]/div/div/span[1]')\n",
    "    # 별점\n",
    "    place_star =  find_element('//*[@id=\"mArticle\"]/div[6]/div[1]/div/em')\n",
    "    # 영업 시간\n",
    "    operating_time = find_element('//*[@id=\"mArticle\"]/div[1]/div[2]/div[2]/div/div[1]/ul/li/span/span[1]')\n",
    "    \n",
    "    # 데이터를 dict 형태로 저장\n",
    "    data_dict = {\n",
    "        \"place_name\": place_name,\n",
    "        \"place_location\": place_location,\n",
    "        \"place_feature\": place_feature,\n",
    "        \"place_star\": place_star,\n",
    "        \"operating_time\": operating_time\n",
    "    }\n",
    "\n",
    "    return print(data_dict)\n",
    "\n",
    "def main():\n",
    "    global driver, load_wb, review_num\n",
    "\n",
    "    driver.implicitly_wait(1)  # 렌더링 될때까지 기다린다 4초\n",
    "    driver.get('https://map.kakao.com/')  # 주소 가져오기\n",
    "\n",
    "    # 검색할 목록\n",
    "    place_infos = ['용머리해안']\n",
    "    \n",
    "    for i, place in enumerate(place_infos):\n",
    "        # delay\n",
    "        if i % 4 == 0 and i != 0:\n",
    "            sleep(1)\n",
    "#         print(\"#####\", i)\n",
    "        search(place)\n",
    "    \n",
    "    driver.quit()\n",
    "    print(\"finish\")\n",
    "\n",
    "#     # 크롤링된 데이터 모아보기\n",
    "#     crawling_data = place_name, place_location, place_feature, place_star, operating_time\n",
    "#     print(crawling_data)\n",
    "#     return crawling_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29c6af8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제주도 해수욕장\n",
      "1 #### 이호테우해수욕장\n",
      "['이호테우해수욕장', '제주특별자치도 제주시 이호일동 1665-13', '해수욕장,해변', '3.8점', '']\n",
      "2 #### 남원큰엉해변\n",
      "['남원큰엉해변', '제주특별자치도 서귀포시 남원읍 태위로 522-17 (우)63620', '해수욕장,해변', '4.5점', '']\n",
      "3 #### 함덕해수욕장\n",
      "['함덕해수욕장', '제주특별자치도 제주시 조천읍 조함해안로 525 (우)63333', '해수욕장,해변', '4.5점', '']\n",
      "4 #### 협재해수욕장\n",
      "['협재해수욕장', '제주특별자치도 제주시 한림읍 한림로 329-10 (우)63011', '해수욕장,해변', '4.6점', '']\n",
      "5 #### 용머리해안\n",
      "['용머리해안', '제주특별자치도 서귀포시 안덕면 사계리', '해수욕장,해변', '4.6점', '09:00 ~ 17:00']\n",
      "1 #### 황우지해안\n",
      "['황우지해안', '제주특별자치도 서귀포시 천지동 765-7', '해수욕장,해변', '4.2점', '']\n",
      "2 #### 삼양해수욕장\n",
      "['삼양해수욕장', '제주특별자치도 제주시 삼양이동 1960-4', '해수욕장,해변', '4.5점', '']\n",
      "3 #### 행원해변\n",
      "['행원해변', '제주특별자치도 제주시 구좌읍 행원리 575-6', '해수욕장,해변', '4.0점', '']\n",
      "4 #### 논짓물해변\n",
      "['논짓물해변', '제주특별자치도 서귀포시 하예동 532-3', '해수욕장,해변', '3.8점', '']\n",
      "5 #### 검멀레해변\n",
      "['검멀레해변', '제주특별자치도 제주시 우도면 연평리', '해수욕장,해변', '4.6점', '']\n",
      "1 #### 몽돌해변\n",
      "['몽돌해변', '제주특별자치도 제주시 내도동 465-2', '해수욕장,해변', '3.3점', '']\n",
      "2 #### 세기알해변\n",
      "['세기알해변', '제주특별자치도 제주시 구좌읍 김녕리 1200-5', '해수욕장,해변', '4.9점', '']\n",
      "3 #### 신흥해수욕장\n",
      "['신흥해수욕장', '제주특별자치도 제주시 조천읍 신흥리', '해수욕장,해변', '4.5점', '']\n",
      "4 #### 하모해변\n",
      "['하모해변', '제주특별자치도 서귀포시 대정읍 하모리', '해수욕장,해변', '3.4점', '']\n",
      "5 #### 알작지해변\n",
      "['알작지해변', '제주특별자치도 제주시 내도동 465-2', '해수욕장,해변', '3.8점', '']\n",
      "1 #### 함덕해수욕장 주차장\n",
      "['함덕해수욕장 주차장', '제주특별자치도 제주시 조천읍 함덕리 1004-5', '주차장', '', '']\n",
      "2 #### 협재해수욕장 주차장\n",
      "['협재해수욕장 주차장', '제주특별자치도 제주시 한림읍 협재리 2447-22', '주차장', '', '']\n",
      "3 #### 협재해수욕장 캠핑장\n",
      "['협재해수욕장 캠핑장', '제주특별자치도 제주시 한림읍 협재리', '야영,캠핑장', '4.6점', '']\n",
      "4 #### 곽지해수욕장 주차장\n",
      "['곽지해수욕장 주차장', '제주특별자치도 제주시 애월읍 곽지리 1565', '주차장', '', '']\n",
      "5 #### 세화해수욕장 주차장\n",
      "['세화해수욕장 주차장', '제주특별자치도 제주시 구좌읍 세화리 1381-5', '주차장', '', '']\n",
      "1 #### 김녕해수욕장 야영장주차장2\n",
      "['김녕해수욕장 야영장주차장2', '제주특별자치도 제주시 구좌읍 해맞이해안로 7-6 (우)63357', '주차장', '', '']\n",
      "2 #### 삼양해수욕장 정자\n",
      "['삼양해수욕장 정자', '제주특별자치도 제주시 삼양일동 1624-17', '관광지부속시설', '', '']\n",
      "3 #### 삼양해수욕장 공영주차장\n",
      "['삼양해수욕장 공영주차장', '제주특별자치도 제주시 삼양일동 1569-24', '공영주차장', '5.0점', '']\n",
      "4 #### 하도해수욕장 화장실\n",
      "['하도해수욕장 화장실', '제주특별자치도 제주시 구좌읍 해맞이해안로 1973 (우)63363', '화장실', '', '']\n",
      "5 #### 이호테우해수욕장 화장실\n",
      "['이호테우해수욕장 화장실', '제주특별자치도 제주시 이호일동 431-2', '화장실', '', '']\n",
      "finish\n",
      "Data saved to top_25_places_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('lang=ko_KR')\n",
    "chromedriver_path = \"C:/chromedriver\"\n",
    "driver = webdriver.Chrome(os.path.join(os.getcwd(), chromedriver_path), options=options)\n",
    "\n",
    "def search(place):\n",
    "    global driver\n",
    "\n",
    "    search_area = driver.find_element_by_xpath('//*[@id=\"search.keyword.query\"]')\n",
    "    search_area.send_keys(place)\n",
    "    driver.find_element_by_xpath('//*[@id=\"search.keyword.submit\"]').send_keys(Keys.ENTER)\n",
    "    sleep(1)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    place_lists = soup.select('.placelist > .PlaceItem')\n",
    "\n",
    "    crawling(place, place_lists[:5])\n",
    "    search_area.clear()\n",
    "\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"info.search.place.more\"]').send_keys(Keys.ENTER)\n",
    "        sleep(1)\n",
    "\n",
    "        for i in range(2, 6):\n",
    "            xPath = '//*[@id=\"info.search.page.no' + str(i) + '\"]'\n",
    "            driver.find_element_by_xpath(xPath).send_keys(Keys.ENTER)\n",
    "            sleep(1)\n",
    "\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            place_lists = soup.select('.placelist > .PlaceItem')\n",
    "\n",
    "            crawling(place, place_lists[:5])\n",
    "\n",
    "    except ElementNotInteractableException:\n",
    "        print('not found')\n",
    "    finally:\n",
    "        search_area.clear()\n",
    "\n",
    "def crawling(place, place_lists):\n",
    "    global driver, all_data\n",
    "\n",
    "    for i, place in enumerate(place_lists):\n",
    "        place_name = place.select('.head_item > .tit_name > .link_name')[0].text\n",
    "\n",
    "        detail_page_xpath = '//*[@id=\"info.search.place.list\"]/li[' + str(i + 1) + ']/div[5]/div[4]/a[1]'\n",
    "        driver.find_element_by_xpath(detail_page_xpath).send_keys(Keys.ENTER)\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        sleep(1)\n",
    "\n",
    "        print(i+1, '.', place_name)        \n",
    "        \n",
    "        data_dict = extract_data()\n",
    "\n",
    "        if data_dict:\n",
    "            all_data.append(data_dict)\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "def find_element(xpath):\n",
    "    global driver\n",
    "\n",
    "    try:\n",
    "        element = driver.find_element_by_xpath(xpath)\n",
    "        return element.text\n",
    "    except NoSuchElementException:\n",
    "        return \"\"\n",
    "\n",
    "def extract_data():\n",
    "    global driver\n",
    "\n",
    "    place_name = find_element('//*[@id=\"mArticle\"]/div[1]/div[1]/div[2]/div/h2')\n",
    "    place_location = find_element('//*[@id=\"mArticle\"]/div[1]/div[2]/div[1]/div/span[1]')\n",
    "    place_feature = find_element('//*[@id=\"mArticle\"]/div[1]/div[1]/div[2]/div/div/span[1]')\n",
    "    place_star =  find_element('//*[@id=\"mArticle\"]/div[5]/div[1]/div/em')\n",
    "    operating_time = find_element('//*[@id=\"mArticle\"]/div[1]/div[2]/div[2]/div/div[1]/ul/li/span/span[1]')\n",
    "\n",
    "    crawling_data = [place_name, place_location, place_feature, place_star, operating_time]\n",
    "    \n",
    "    if place_name:\n",
    "        data_dict = {\"place_name\": place_name,\n",
    "            \"place_location\": place_location,\n",
    "            \"place_feature\": place_feature,\n",
    "            \"place_star\": place_star,\n",
    "            \"operating_time\": operating_time}\n",
    "        return data_dict, print(crawling_data)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    global driver, all_data\n",
    "    all_data = []\n",
    "    driver.implicitly_wait(1)\n",
    "    driver.get('https://map.kakao.com/')\n",
    "    \n",
    "    place_infos = [input(\"\")]\n",
    "    place_infos_str = \"\".join(place_infos)\n",
    "\n",
    "    for i, place in enumerate(place_infos):\n",
    "        if i % 4 == 0 and i != 0:\n",
    "            sleep(1)\n",
    "        search(place)\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"finish\")\n",
    "\n",
    "    # Save all_data to a CSV file\n",
    "    if all_data:\n",
    "        data_frame = pd.DataFrame(all_data)\n",
    "        data_frame.to_csv('top_25_places_data_' + place_infos_str + '.csv', index=False, encoding='utf-8-sig')\n",
    "        print(\"Data saved to top_25_places_data.csv\")\n",
    "    else:\n",
    "        print(\"No data to save\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2498c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
